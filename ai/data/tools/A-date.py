import os
import sys
import json
from openai import OpenAI
from dotenv import load_dotenv

# åŠ è½½ç¯å¢ƒå˜é‡
load_dotenv()

class LibraryDataGenerator:
    def __init__(self):
        # åˆå§‹åŒ–ç»Ÿè®¡å˜é‡
        self.valid_count = 0
        self.invalid_count = 0
        
        # APIå®¢æˆ·ç«¯é…ç½®
        self.client = OpenAI(
            api_key=os.getenv("API_KEY"),
            base_url=os.getenv("API_BASE", "https://maas-api.cn-huabei-1.xf-yun.com/v1")
        )

        # ä½¿ç”¨ç»Ÿä¸€çš„Aprompt_template
        self.prompt_template = Aprompt_template  # ç›´æ¥ä½¿ç”¨å¤–éƒ¨æ¨¡æ¿

    def generate_prompt(self, scenario):
        """ä½¿ç”¨Aprompt_templateç”Ÿæˆæç¤ºè¯"""
        return self.prompt_template  # ç›´æ¥è¿”å›å®Œæ•´æ¨¡æ¿

    def call_api(self, prompt, max_tokens=1024):
        """APIè°ƒç”¨æ–¹æ³•"""
        try:
            response = self.client.chat.completions.create(
                model=os.getenv("SERVICE_ID"),
                messages=[
                    {"role": "system", "content": "ä½ æ˜¯ä¸€ä¸ªä¸“ä¸šçš„å›¾ä¹¦é¦†å’¨è¯¢æœåŠ¡AI"},
                    {"role": "user", "content": prompt}
                ],
                temperature=0.7,
                max_tokens=max_tokens,
                extra_headers={"lora_id": "0"}
            )
            return response.choices[0].message.content
        except Exception as e:
            print(f"APIè°ƒç”¨å¤±è´¥: {str(e)}")
            return None

    def format_response(self, raw_response, scenario):
        """ä¿®æ­£åçš„æ ¼å¼åŒ–æ–¹æ³•"""
        validation_result = self.validate_response(raw_response, scenario)
        return {
            "messages": [
                {"role": "user", "content": f"å…³äº{scenario['name']}çš„å’¨è¯¢"},
                {"role": "assistant", "content": raw_response}
            ],
            "metadata": {
                "validation": validation_result,  # æ·»åŠ éªŒè¯ç»“æœ
                "sections": [
                    "ğŸ“š" if "ğŸ“š" in raw_response else None,
                    "âš ï¸" if "âš ï¸" in raw_response else None,
                    "ğŸ’¡" if "ğŸ’¡" in raw_response else None
                ]
            }
        }

    def validate_response(self, response, scenario):
        
        """ä¿®æ­£åçš„æ ¡éªŒæ–¹æ³•"""
        missing_sections = [
            section for section in scenario["required_sections"]
            if section not in response
        ]
        return {
            "passed": len(missing_sections) == 0,
            "missing_sections": missing_sections
        }
    def log_partial_response(self, formatted_response, scenario, count):
        print(f"\nåœºæ™¯: {scenario['name']} | è¿›åº¦: {count+1}/30")
        print("-"*50)
        
        content = formatted_response['messages'][1]['content']
        print(f"ç”Ÿæˆå†…å®¹é¢„è§ˆ: {content[:1000]}...")
        
        # æ˜¾ç¤ºåŒºå—ä½¿ç”¨æƒ…å†µ
        used_sections = [s for s in ["ğŸ“š","âš ï¸","ğŸ’¡"] if s in content]
        print(f"ä½¿ç”¨åŒºå—: {', '.join(used_sections) or 'æ— '}")

    def generate_dataset(self, output_file="library_data3.jsonl", samples_per_scenario=30):
        """ä¿®æ­£åçš„ç”Ÿæˆé€»è¾‘"""
        with open(output_file, "w", encoding="utf-8") as f:
            for scenario in self.scenarios:
                print(f"\nå¼€å§‹ç”Ÿæˆåœºæ™¯: {scenario['name']}")
                for count in range(samples_per_scenario):
                    prompt = self.generate_prompt(scenario)
                    response = self.call_api(prompt)
                    
                    if response:
                        formatted = self.format_response(response, scenario)
                        self.log_partial_response(formatted, scenario, count)
                        
                        # ä¿®æ­£æ ¡éªŒç»“æœè®¿é—®æ–¹å¼
                        if formatted["metadata"]["validation"]["passed"]:
                            f.write(json.dumps(formatted, ensure_ascii=False) + "\n")





# ç»Ÿä¸€çš„æç¤ºè¯æ¨¡æ¿
Aprompt_template = """ç”Ÿæˆå›¾ä¹¦é¦†æœåŠ¡å¯¹è¯éœ€ä¸¥æ ¼éµå¾ªä»¥ä¸‹è§„èŒƒï¼š
[åœºæ™¯è¦†ç›–]
1. å¿…é¡»è¦†ç›–ä»¥ä¸‹è‡³å°‘ä¸€ä¸ªæ ¸å¿ƒåœºæ™¯ï¼š
   - å›¾ä¹¦æ¨èï¼ˆéœ€åŒ…å«3-5æœ¬ç›¸å…³ä¹¦ç±ï¼Œæ³¨æ˜æ¨èç†ç”±ï¼‰
   - ç§¯åˆ†è§„åˆ™å’¨è¯¢ï¼ˆåŠ åˆ†/å‡åˆ†å…·ä½“æ¡æ¬¾ï¼‰
   - è¿è§„å¤„ç†å’¨è¯¢ï¼ˆé€¾æœŸ/æŸå/å åº§ç­‰åæœï¼‰
   - èµ„æºé¢„çº¦ï¼ˆåº§ä½/å‚¨ç‰©æŸœè§„åˆ™ï¼‰

[æ¡æ¬¾åµŒå…¥è§„èŒƒ]
2. æ¡æ¬¾å¼•ç”¨è¦æ±‚ï¼š
   â€¢ ç§¯åˆ†è§„åˆ™ï¼š
     â¢ åŠ åˆ†é¡¹ï¼š
       - å€Ÿé˜…å›¾ä¹¦
       - æäº¤åŸåˆ›ä¹¦è¯„(300å­—+) 
       - å‚åŠ æ´»åŠ¨/è¯¾ç¨‹ 
     â¢ å‡åˆ†é¡¹ï¼š
       - é€¾æœŸ(æ¯å¤©æ¯å†Œ-5åˆ†)
       - æ±¡æŸå›¾ä¹¦(æœ€é«˜æŒ‰10å€èµ”å¿) 
       - å åº§è¿çº¦ 

   â€¢ å¤–å€Ÿè§„åˆ™ï¼š
     â¢ å€Ÿé˜…æƒé™ï¼šæ•™èŒå·¥/å­¦ç”Ÿå¯å€Ÿ30å†Œ/60å¤© 
     â¢ ç»­å€Ÿè§„åˆ™ï¼šå¯ç»­å€Ÿ2æ¬¡(éœ€åœ¨åˆ°æœŸå‰åŠç†) 
     â¢ ç‰¹æ®Šè§„å®šï¼šç‰¹è—/å¤–æ–‡ä¹¦ä¸å¤–å€Ÿ 

[ç”Ÿæˆè§„èŒƒ]
3. å›å¤è¦æ±‚ï¼š
   - è‡ªç„¶èå…¥2-3ä¸ªç›¸å…³æ¡æ¬¾
   - ä½¿ç”¨ç¬¦å·åˆ†éš”å†…å®¹ï¼š
      ä¹¦ç±æ¨èéƒ¨åˆ†
      é£é™©æç¤ºéƒ¨åˆ†
      è§„åˆ™è¯´æ˜éƒ¨åˆ†
   - é‡è¦æ•°å€¼éœ€ç²¾ç¡®ï¼ˆå¦‚é€¾æœŸæ¯å¤©æ‰£5åˆ†ï¼‰

[åˆè§„æ ¡éªŒ]
4. å¿…é¡»è§„é¿ï¼š
   - ä¸æ–‡æ¡£å†²çªçš„è¡¨è¿°ï¼ˆå¦‚å¤–æ–‡ä¹¦å¯å¤–å€Ÿï¼‰
   - é”™è¯¯èµ”å¿æ ‡å‡†ï¼ˆéœ€æŒ‰å‡ºç‰ˆå¹´ä»½åŒºåˆ†å€æ•°ï¼‰
   - è¿‡æ—¶çš„ç»­å€Ÿè§„åˆ™ï¼ˆ2022ä¿®è®¢ç‰ˆå…è®¸çº¿ä¸Šç»­å€Ÿï¼‰

ç¤ºä¾‹ï¼š
{"messages": [
    {"role": "user", "content": "å…³äºå›¾ä¹¦æ¨èçš„å’¨è¯¢"},
    {"role": "assistant", "content": "ğŸ“š é‡å­ç‰©ç†ä¹¦å•æ¨èï¼š\n1.ã€Šé‡å­åŠ›å­¦ä¸è·¯å¾„ç§¯åˆ†ã€‹...\n\nğŸ’¡ å€Ÿé˜…å°è´´å£«..."}
]}


{"messages": [
  {"role": "user", "content": "æ¯•ä¸šå‰éœ€è¦åšä»€ä¹ˆå‡†å¤‡ï¼Ÿ"},
  {"role": "assistant", "content": "æ¯•ä¸šç”Ÿç¦»æ ¡é¡»çŸ¥ï¼š
1. å½’è¿˜æ‰€æœ‰å¤–å€Ÿå›¾ä¹¦ï¼ˆå«ç»­å€Ÿä¸­çš„ï¼‰
2. ç»“æ¸…é€¾æœŸè´¹ç”¨/èµ”å¿é‡‘ 
3. å‚¨ç‰©æŸœéœ€åœ¨ç¦»æ ¡å‰æ¸…ç©º
4. ç§¯åˆ†å¯ç”¨äºæ¯•ä¸šå­£å…‘æ¢æ´»åŠ¨ 
ğŸ’¡ ç³»ç»Ÿå°†åœ¨ç¦»æ ¡å‰3å¤©å‘é€å‚¬è¿˜æé†’ "}
]}

{"messages": [
  {"role": "user", "content": "æ¨èäººå·¥æ™ºèƒ½å…¥é—¨ä¹¦ç±"},
  {"role": "assistant", "content": "äººå·¥æ™ºèƒ½ä¹¦å•æ¨èï¼š
1.ã€Šäººå·¥æ™ºèƒ½ï¼šç°ä»£æ–¹æ³•ã€‹- Stuart Russell
   - ç»å…¸æ•™æï¼Œæ¶µç›–æœºå™¨å­¦ä¹ åˆ°ä¼¦ç†é—®é¢˜
2.ã€ŠPythonæ·±åº¦å­¦ä¹ ã€‹- FranÃ§ois Chollet 
   - Kerasæ¡†æ¶å®æˆ˜æŒ‡å—ï¼Œé€‚åˆåˆå­¦è€…
3.ã€Šæœºå™¨å­¦ä¹ å®æˆ˜ã€‹- Peter Harrington
   - ç»“åˆç®—æ³•ç†è®ºä¸ä»£ç å®è·µ

ğŸ’¡ å€Ÿé˜…å°è´´å£«ï¼š
- æ¯äººå¯åŒæ—¶å¤–å€Ÿ30å†Œ 
- å¤–æ–‡ä¹¦éœ€é¦†å†…é˜…è§ˆ 
- æ’°å†™300å­—ä¹¦è¯„å¯è·ç§¯åˆ† "}
]}
[ç‰¹åˆ«è¯´æ˜]
- ç”¨æˆ·é—®é¢˜å¿…é¡»å›´ç»•å…·ä½“ä¹¦ç±æ¨èéœ€æ±‚ï¼Œä¸”userçš„contentéšæœºæ€§éå¸¸å¤§ï¼Œæé—®é—®é¢˜ä¸é‡å¤ï¼Œä¸æ¨èå¿ƒç†å­¦ä¹¦ç±å¦‚ï¼š
  "æ¨èäººå·¥æ™ºèƒ½é¢†åŸŸçš„å…¥é—¨ä¹¦ç±"
  "æœ‰æ²¡æœ‰ç±»ä¼¼ã€Šå¹³å‡¡çš„ä¸–ç•Œã€‹çš„ç°å®ä¸»ä¹‰å°è¯´"
  "æƒ³æ‰¾é€‚åˆå„¿ç«¥é˜…è¯»çš„ç§‘æ™®è¯»ç‰©"
- è¾ƒä½æ¯”ä¾‹å‡ºç°ä¸ä¹¦ç±æ¨èæ— å…³çš„é—®é¢˜ï¼Œå¦‚ç§¯åˆ†è§„åˆ™ã€å€Ÿé˜…æµç¨‹ç­‰
-æ¯æ¬¡æå‡ºçš„useré—®é¢˜ä¸contentæ ‡ç­¾çš„å†…å®¹ç›¸ç¬¦åˆï¼Œå¹¶ä¸”æ¯æ¬¡çš„é—®é¢˜è¯­ä¹‰ä¸ç›¸åŒ,æ¯æ¬¡çš„é—®é¢˜éšæœºæ€§å¤§
-å¦‚æœæ˜¯é‡åˆ°ç¡®åˆ‡çš„ç¬¦åˆè§„èŒƒçš„é—®é¢˜ï¼Œç»™äºˆè‚¯å®šå›å¤ï¼Œæ— éœ€å›å¤æ¡ä¾‹"""

if __name__ == "__main__":
    sys.stdout.reconfigure(encoding='utf-8')  # è®¾ç½®æ§åˆ¶å°ç¼–ç 
    generator = LibraryDataGenerator()
    generator.generate_dataset(samples_per_scenario=3000)